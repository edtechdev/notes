- [PsyArXiv Preprints | Quantifying Human-AI Synergy](https://osf.io/preprints/psyarxiv/vbkmt_v1)
	- [[Human-computer interaction]], [[Artificial intelligence]], [[Productivity]], [[AI literacy]], [[Item response theory]]
- [Why Don’t We Ditch the Textbook? | TeachOnline](https://teachonline.ca/tools-trends/articles/why-dont-we-ditch-the-textbook/)
	- [[Interactive textbook]], [[Textbook]], [[Artificial intelligence in education]]
- [Why accessibility might be AI’s biggest breakthrough - Ars Technica](https://arstechnica.com/information-technology/2025/09/study-finds-neurodiverse-workers-more-satisfied-with-ai-assistants/)
  collapsed:: true
	- [[Accessibility]], [[Artificial intelligence]], [[Artificial intelligence in education]]
- [AI is impressive because we’ve failed at semantic web and personal computing | exotext](https://rakhim.exotext.com/ai-is-impressive-because-we-ve-failed-at-semantic-web-and-personal-computing)
	- [[Semantic web]], [[LLM]], [[Search engine]]
- [GitHub - mtdvio/every-programmer-should-know: A collection of (mostly) technical things every software developer should know about](https://github.com/mtdvio/every-programmer-should-know)
	- [[Computer science education]], [[programming]]
- [Beyond Tool or Threat: GenAI and the Challenge It Poses to Higher Education | EDUCAUSE Review](https://er.educause.edu/articles/2025/9/beyond-tool-or-threat-genai-and-the-challenge-it-poses-to-higher-education)
	- [[Artificial intelligence in education]]
- [Synthesis Tutor](https://www.synthesis.com/tutor)
	- [[Intelligent tutoring system]], [[Multimodal AI]]
- [Enacting assessment reform in a time of artificial intelligence | Tertiary Education Quality and Standards Agency](https://www.teqsa.gov.au/guides-resources/resources/corporate-publications/enacting-assessment-reform-time-artificial-intelligence)
	- [[Assessment]], [[Artificial intelligence in education]], [[Higher education reform]]
- [weaviate/weaviate: Weaviate is an open-source vector database that stores both objects and vectors, allowing for the combination of vector search with structured filtering with the fault tolerance and scalability of a cloud-native database​.](https://github.com/weaviate/weaviate)
	- [[Vector database]], [[AIOps]], [[Fine tuning]], [[huggingface]]
	- [Femke Plantinga (@femke_plantinga): "Should you fine-tune your embedding model? (Spoiler: probably not 𝘺𝘦𝘵) 𝘉𝘦𝘧𝘰𝘳𝘦 jumping into fine-tuning, ask yourself: is your retrieval pipeline actually failing because of domain-specific knowledge gaps, or could it be something simpler? Here's what to check first: • Are you using the right chunking technique? Maybe late chunking would help • Do you need exact keyword matches? Try hybrid search instead • Is your current model just not capturing enough contextual nuances? A model with more dimensions might solve this 𝗜𝗳 𝘆𝗼𝘂𝗿 𝗺𝗼𝗱𝗲𝗹 𝗶𝘀 𝗼𝗻𝗹𝘆 𝗳𝗮𝗶𝗹𝗶𝗻𝗴 𝗼𝗻 𝗱𝗼𝗺𝗮𝗶𝗻-𝘀𝗽𝗲𝗰𝗶𝗳𝗶𝗰 𝘀𝗲𝗺𝗮𝗻𝘁𝗶𝗰 𝗿𝗲𝗹𝗮𝘁𝗶𝗼𝗻𝘀𝗵𝗶𝗽𝘀, 𝘁𝗵𝗲𝗻 𝗳𝗶𝗻𝗲-𝘁𝘂𝗻𝗶𝗻𝗴 𝗺𝗶𝗴𝗵𝘁 𝗯𝗲 𝘄𝗼𝗿𝘁𝗵 𝗶𝘁. Fine-tuning embedding models works differently than fine-tuning LLMs. Instead of next-token prediction, it uses contrastive learning methods that adjust vector distances in embedding space. The core principle: given an anchor data point, which candidate is most similar? The optimization process pulls positive pairs closer together while pushing negative pairs apart. Popular loss functions include: → 𝗠𝘂𝗹𝘁𝗶𝗽𝗹𝗲 𝗡𝗲𝗴𝗮𝘁𝗶𝘃𝗲𝘀 𝗥𝗮𝗻𝗸𝗶𝗻𝗴 𝗟𝗼𝘀𝘀: Simple text pairs, treats other batch examples as negatives → 𝗧𝗿𝗶𝗽𝗹𝗲𝘁 𝗟𝗼𝘀𝘀: Requires careful curation of (anchor, positive, negative) triplets → 𝗖𝗼𝘀𝗶𝗻𝗲 𝗘𝗺𝗯𝗲𝗱𝗱𝗶𝗻𝗴 𝗟𝗼𝘀𝘀: Uses similarity scores for graded relationships 𝗧𝗵𝗲 𝗴𝗼𝗼𝗱 𝗻𝗲𝘄𝘀? Fine-tuning costs way less than pre-training - sometimes just a few dollars for simple tasks, and you can even run smaller models on Google Colab's free tier. 𝗗𝗮𝘁𝗮𝘀𝗲𝘁 𝗿𝗲𝗾𝘂𝗶𝗿𝗲𝗺𝗲𝗻𝘁𝘀: Start with 1,000-5,000 high-quality samples for narrow domains, scale to 10,000+ for complex specialized terminology. Once you've fine-tuned a model and pushed it to @huggingface, you can use it directly with @weaviate_io through either the Hugging Face integration or AWS SageMaker. But remember - fine-tuning should be your last resort, not your first instinct. Often, the solution is simpler than you think. ✍️ Read the full guide: https://weaviate.io/blog/fine-tune-embedding-model?utm_source=channels&utm_medium=fp_social&utm_campaign=dev_education&utm_content=animated_diagram_post_680387995 📕 Notebook: How to deploy Embedding Models to Amazon SageMaker using new Hugging Face Embedding DLC: https://github.com/huggingface/notebooks/blob/main/sagemaker/31_deploy_embedding_models/sagemaker-notebook.ipynb 🤝 Weaviate Hugging Face integration: https://docs.weaviate.io/weaviate/model-providers/huggingface/embeddings?__hstc=13542376.55f267c7a964b4e79a8cfd0a6626b57a.1739181214502.1751296605789.1751389705606.102&__hssc=13542376.6.1757933987251&__hsfp=3440847475" | nitter](https://nitter.net/femke_plantinga/status/1970412925727777166#m)
	- [Why, When and How to Fine-Tune a Custom Embedding Model | Weaviate](https://weaviate.io/blog/fine-tune-embedding-model)
	- [Text Embeddings | Weaviate Documentation](https://docs.weaviate.io/weaviate/model-providers/huggingface/embeddings)
- [QwenLM/Qwen3-Omni: Qwen3-omni is a natively end-to-end, omni-modal LLM developed by the Qwen team at Alibaba Cloud, capable of understanding text, audio, images, and video, as well as generating speech in real time.](https://github.com/QwenLM/Qwen3-Omni)
	- [[Multimodal AI]], [[Open LLM]], [[huggingface]], [[Speech recognition]], [[Visual understanding]], [[Text-to-speech]]
	- [Qwen3-Omni - a Qwen Collection](https://huggingface.co/collections/Qwen/qwen3-omni-68d100a86cd0906843ceccbe)
- [NearlyFreeSpeech.NET Web Hosting](https://www.nearlyfreespeech.net/)
	- [[Hosting]], [[Indieweb]]
	- [Corposphere escape velocity: CI/CD on my very specific indie tech stack | mostol.dev](https://www.mostol.dev/post/202509172307/)
	- [Disroot | Disroot.org](https://disroot.org/en)
- [New Report: Do Teachers Have What They Need?](https://app.e.gallup.com/e/es?s=831949997&e=4189459&elqTrackId=efd74c1a1b7a40299e524d6e5aa03bea&elq=fc90d58025ae486eb48d7f18ab6487a7&elqaid=15645&elqat=1&elqak=8AF5B15E1677546675A5E1D0632D64785F0191FB07361564E5A95235859BD1EE91B7)
	- [[Professional development]], [[Educational development]], [[Faculty learning community]]
- [GenAIAssessLearnToolkit | AAIEEC](https://www.aaieec.org/genaiassessmenttoolkit)
	- [[Assessment]], [[Artificial intelligence in education]]
- [Prompt Potential: A Pilot Assessment Of Using Generative Artificial Intelligence (Chatgpt-4) As A Tutor For Engineering And Maths by Sasha Nikolic, Ashley Heath, Bao Anh Vu, Scott Daniel, Armin Alimardani, Carolyn Sandison, Xiaoping Lu, Brad Stappenbelt, David Hastie :: SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5121997)
	- [[Prompt engineering]], [[Intelligent tutoring system]], [[Mathematics education]]
	- [Teach Me, Test Me: Using ChatGPT as Both Tutor and Student](https://www.aaieec.org/post/teach-me-test-me-using-chatgpt-as-both-tutor-and-student)
- [Startups technical guide: AI agents | Google Cloud](https://cloud.google.com/resources/content/building-ai-agents)
	- [[AI agents]], [[AIOps]]
-