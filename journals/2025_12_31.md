- How to Use Notebooklm Better than 99% of People {{video https://youtube.com/watch?v=SogSf-1p9t4&si=PLPxXL2fAZktCdnv}}
	- [[NotebookLM]]
- AI-Detectors Just Changed Everything...Again {{video https://youtube.com/watch?v=L51rkfbJ858&si=Cayq7UTQu6Ex1o4Z}}
	- [[AI detection]]
- 5 Assignment Types that Prevent Student Cheating with AI - 10-Minute AI ... {{video https://youtube.com/watch?v=fJj1juPimOA&si=ylnqF83Fpu257Loi}}
	- [[Cheating]], [[Artificial intelligence in education]], [[Assignment]]
	- [5 Assignment Types that Prevent Cheating with AI – EdAINow](https://www.edainow.com/non-ai-assignments/)
	- Preventing Student Cheating with AI - strategies to make sure students d... {{video https://youtube.com/watch?v=nbyqDaCkWf0&si=K3ozZnyJahE7Hnjk}}
- [Animated AI](https://animatedai.github.io/)
	- [[Animation]], [[Simulation]], [[AI literacy]], [[Neural network]], [[Artificial intelligence]]
	- [Animated AI | Hacker News](https://news.ycombinator.com/item?id=46390621)
- [[2512.16917] Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning](https://arxiv.org/abs/2512.16917)
	- [[Reasoning]], [[LLM]], [[Mathematics]], [[Reinforcement learning]], [[LLM training]], [[Adversarial collaboration]], [[Logic]]
	- [Rohan Paul (@rohanpaul_ai): "New Johns Hopkins University paper's Generative Adversarial Reasoner trains a math solving LLM with a critic, so the reasoner learns to stop making bad logic moves. It fixes the usual "only final answer gets graded" problem by teaching the model with step by step feedback, so it actually learns better reasoning instead of guessing. AIME24 is a hard contest math benchmark, and accuracy rose from 54.0 to 61.3. An LLM is a text model that predicts the next word, and it can make steps that sound right while being wrong. Reinforcement learning trains by giving a score after an answer, but many setups only score the final answer, so the model does not learn where the logic broke. The main LLM is the reasoner, and the paper adds a 2nd model, a discriminator, to score small slices as yes or no. Those slice scores become extra reward, so good partial reasoning gets rewarded even when the final answer is still off. Both models train together, and the discriminator also learns by trying to tell generated slices from reference solutions, which keeps its judging sharp. Later, only the reasoner is used to answer questions, so the extra judging cost stays in training. ---- Paper Link – arxiv. org/abs/2512.16917 Paper Title: "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning"" | nitter](https://nitter.net/rohanpaul_ai/status/2005967850356498481#m)
	- [TRIDENT: Thought-based Reasoning and Improvement through Deep Exploration of Neuronal Trees - Shivik](https://www.shivik.in/shivik-labs/trident)
- [Building low-level software with only coding agents | Lee Robinson](https://leerob.com/pixo)
	- [[Code generation]], [[Vibe coding]], [[AI agents]], [[Image editor]], [[Webassembly]], [[Rust]], [[svelte]], [[Web development]], [[Local first software]], [[Content management system]], [[React]], [[next.js]], [[Markdown]]
	- [Coding Agents & Complexity Budgets | Lee Robinson](https://leerob.com/agents)
	- [leerob/pixo: High-performance image compression library written in Rust.](https://github.com/leerob/pixo)
	- [pixo::guides::introduction_to_image_compression - Rust](https://docs.rs/pixo/latest/pixo/guides/introduction_to_image_compression/index.html)
	- [pixo::guides::introduction_to_rust - Rust](https://docs.rs/pixo/latest/pixo/guides/introduction_to_rust/index.html)
- [timescale/pg-aiguide: MCP server and Claude plugin for Postgres skills and documentation. Helps AI coding tools generate better PostgreSQL code.](https://github.com/timescale/pg-aiguide)
	- [[postgresql]], [[Database]], [[Model context protocol]], [[Code generation]], [[Claude]]
- [Claude Code: A Highly Agentic Coding Assistant - DeepLearning.AI](https://www.deeplearning.ai/short-courses/claude-code-a-highly-agentic-coding-assistant/)
	- [[Claude]], [[Code generation]], [[AI agents]]
- [[2512.18202] Sophia: A Persistent Agent Framework of Artificial Life](https://arxiv.org/abs/2512.18202)
	- [[AI agents]], [[Reasoning]], [[Metacognition]], [[Autonomy]], [[Intrinsic motivation]]
	- [DAIR.AI (@dair_ai): "This paper is worth reading carefully. It introduces System 3 for AI Agents. The default approach to LLM agents today relies on System 1 for fast perception and System 2 for deliberate reasoning. But they remain static after deployment. No self-improvement. No identity continuity. No intrinsic motivation to learn beyond assigned tasks. This new research introduces Sophia, a persistent agent framework built on a proposed System 3: a meta-cognitive layer that maintains narrative identity, generates its own goals, and enables lifelong adaptation. Artificial life requires four psychological foundations mapped to computational modules: - Meta-cognition monitors and audits ongoing reasoning. - Theory-of-mind models users' beliefs and intentions. - Intrinsic motivation drives curiosity-based exploration. - Episodic memory maintains autobiographical context across sessions. Here is how it works: > Process-Supervised Thought Search captures and validates reasoning traces. > A Memory Module maintains a structured graph of goals and experiences. > Self and User Models track capabilities and beliefs. > A Hybrid Reward Module blends external task feedback with intrinsic signals like curiosity and mastery. In a 36-hour continuous deployment, Sophia demonstrated persistent autonomy. During user idle periods, the agent shifted entirely to self-generated tasks. Success rate on hard tasks jumped from 20% to 60% through autonomous self-improvement. Reasoning steps for recurring problems dropped 80% through episodic memory retrieval. This moves agents from transient problem-solvers to adaptive entities with coherent identity, transparent introspection, and open-ended competency growth. Paper: https://arxiv.org/abs/2512.18202 Learn to build effective AI agents in our academy: https://dair-ai.thinkific.com/" | nitter](https://nitter.net/dair_ai/status/2004907378446381304#m)
	- [DAIR.AI](https://dair-ai.thinkific.com/)
- [History and Future of the LMS: Argument and Counter-Argument](https://ailearninsights.substack.com/p/history-and-future-of-the-lms-argument?publication_id=1984256&post_id=183071977&isFreemail=true&r=1gwis&triedRedirect=true)
	- [[LMS]], [[Future of higher education]], [[History of technology]]
	- [LMS at 30 Part 2: Learning Management in the AI Era](https://onedtech.philhillaa.com/p/lms-at-30-part-2-learning-management-in-the-ai-era)
- [Atmospheric Computing | Paul's Dev Notes](https://www.pfrazee.com/blog/atmospheric-computing)
	- [[Bluesky]]
-