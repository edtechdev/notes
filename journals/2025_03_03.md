- [Tencent/Tencent-XR-3DGen](https://github.com/Tencent/Tencent-XR-3DGen)
	- [[3D generation]], [[Open LLM]]
- [EgoLife - a lmms-lab Collection](https://huggingface.co/collections/lmms-lab/egolife-67c04574c2a9b64ab312c342)
	- [[AI assistant]], [[Visual understanding]], [[Multimodal AI]], [[Open LLM]], [[huggingface]]
	- [EgoLife](https://egolife-ai.github.io/)
	- [EvolvingLMMs-Lab/EgoLife: [CVPR 2025] EgoLife: Towards Egocentric Life Assistant](https://github.com/EvolvingLMMs-Lab/EgoLife)
	- [LMMs-Lab](https://lmms-lab.framer.ai/)
- [tinylm - Run Models Locally with WebGPU](https://tinylm.wizenheimer.dev/)
	- [[Local AI]], [[huggingface]], [[WebGPU]], [[javascript]], [[Open LLM]], [[WebGL]]
- [Common AI Model Formats](https://huggingface.co/blog/ngxson/common-ai-model-formats)
	- [[LLM]], [[Open LLM]], [[AIOps]]
- [2024 EDUCAUSE Horizon Report | Cybersecurity and Privacy Edition | EDUCAUSE Library](https://library.educause.edu/resources/2024/9/2024-educause-horizon-report-cybersecurity-and-privacy-edition)
	- [[Cybersecurity]], [[Privacy]], [[Information technology]]
- [Hallucinations in code are the least dangerous form of LLM mistakes](https://simonwillison.net/2025/Mar/2/hallucinations-in-code/)
	- [[Hallucination]], [[Code generation]]
- [Notes from my Accessibility and Gen AI podcast appearence](https://simonwillison.net/2025/Mar/2/accessibility-and-gen-ai/)
	- [[Accessibility]], [[Alternative text]], [[Generative AI]]
	- [Accessibility + Gen AI Podcast | Instagram, Facebook | Linktree](https://linktr.ee/a11ygenai)
- [OCTAVE: the first text-to-speech model that understands what it’s saying • Hume AI](https://www.hume.ai/blog/octave-the-first-text-to-speech-model-that-understands-what-its-saying)
	- [[Text-to-speech]]
- [Google Workspace Updates: Enhancing video navigation and accessibility with Google Drive video transcripts](https://workspaceupdates.googleblog.com/2025/02/google-drive-video-transcripts.html?m=1)
	- [[Transcript]], [[Google]], [[Accessibility]]
-