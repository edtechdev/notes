- [What happens when you trust AI for news](https://popular.info/p/what-happens-when-you-trust-ai-for?publication_id=1664&post_id=176877492&isFreemail=true&r=1gwis&triedRedirect=true)
	- [[News]], [[Misinformation]], [[Artificial intelligence]], [[Information literacy]], [[Hallucination]], [[Gemini]], [[ChatGPT]], [[Claude]], [[Search engine]], [[fact check]], [[Sycophancy]]
	- [August 2025 — AI False Claim Monitor - NewsGuard](https://www.newsguardtech.com/ai-monitor/august-2025-ai-false-claim-monitor/)
	- >The 10 leading AI tools repeated false information on topics in the news more than one third of the time — 35 percent — in August 2025, up from 18 percent in August 2024
	- >One of the systemic problems with AI chatbots is that they are overly confident. Increasingly, AI chatbots are unwilling to acknowledge that they do not know the answer to a question. Instead, they make stuff up. A September report from NewsGuard, which monitors online misinformation, found that “non-response rates fell from 31 percent in August 2024 to 0 percent in August 2025.”
- [Trigger warnings spark curiosity more than caution, new research indicates](https://www.psypost.org/trigger-warnings-spark-curiosity-more-than-caution-new-research-indicates/)
	- [[Trigger warning]]
- [Home - Cognimates](https://hackidemia.github.io/cognimates-website/home/)
	- [[Visual programming]], [[CS4All]], [[Scratch]]
-