- [10 things your campus should be doing to launch generative AI - Community College Daily](https://www.ccdaily.com/2024/04/10-things-your-campus-should-be-doing-to-launch-generative-ai/)
	- [[Artificial intelligence in education]], [[Higher education policy]]
- https://docs.google.com/document/d/1QLSMEtZRrDDrbW2huRcBwl4tbA9Ond1yVcto2DgMFUQ/edit?usp=drivesdk
	- [[gpt4]], [[Chatbot]], [[AI assistant]]
	- [AI Tutor Pro | Contact North | Contact Nord](https://www.aitutorpro.ca/)
- [Can AI make college counseling more equitable?](https://www.insidehighered.com/news/admissions/traditional-age/2024/04/08/can-ai-make-college-counseling-more-equitable)
	- [[Artificial intelligence in education]], [[Advising]], [[Counseling]]
- [Self-Hosted Applications and Alternatives](https://selfh.st/apps/)
	- [[Self-hosted application]], [[Open source]]
- [First-Year College Achievement and Graduation Rates for Hispanic and Hispanic First-Generation Students - Angela L. Vaughan, Jordan L. Martell, Brianne T. Dixon, Emma A. French, 2024](https://journals.sagepub.com/doi/abs/10.1177/15381927241241249?journalCode=jhha)
	- [[First year seminar]], [[Hispanic serving institution]], [[Latino students]], [[Student retention]], [[Graduation rate]], [[Achievement]]
- [A Quasiexperimental Analysis of First-Year Seminar Outcomes at a Large University - Rajeeb Das, Erika Schmitt, Michael T. Stephenson, 2024](https://journals.sagepub.com/doi/10.1177/15210251211038591)
	- [[First year seminar]], [[Propensity matching]], [[GPA]], [[Credit hour]]
- [Teaching Learning Strategies to Increase Success of First-Term College Students: The Journal of Experimental Education](https://www.tandfonline.com/doi/full/10.1080/00220973.2010.512318)
	- [[First year seminar]], [[Learning to learn]], [[Student retention]], [[Graduation rate]], [[Struggling students]]
	- [Teaching Learning Strategies to Increase Success of First-Term College Students - Tuckman-Kennedy-2011-Teaching-learning-strategies-to-increase-success-first-term-college-students.pdf](https://dennislearningcenter.osu.edu/files/2014/08/Tuckman-Kennedy-2011-Teaching-learning-strategies-to-increase-success-first-term-college-students.pdf)
	- >graduation rates were 50% higher for students initially in academic difficulty
- [majacinka/autogen-experiments](https://github.com/majacinka/autogen-experiments)
	- [[autogen]]
	- https://youtu.be/byPbxEH5V8E?si=RZZbSOeZeJHYh0QQ
- [Faculty Readiness Sample Page - Faculty Readiness](https://online.suny.edu/facultyreadiness/)
	- [[Online readiness]], [[Online teaching]]
- [Interested in Teaching Online](https://online.suny.edu/interested/)
	- [[Online teaching]], [[Educational development]]
- [Table 2: DEI Practices](https://dei-annotations.notion.site/Table-2-DEI-Practices-0d17702e364246f68066fb4c25930776)
	- [[DEI]], [[Equity]], [[Course design rubric]], [[Evaluating online teaching]]
- [Robots Talk Back, AI Security Risks, Political Deepfakes, and more](https://www.deeplearning.ai/the-batch/issue-241/)
	- [[Autonomous agent]], [[AI assistant]], [[Flow engineering]], [[Human in the loop]]
	- https://twitter.com/AndrewYNg/status/1770897666702233815
	- >My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm’s ability to do well on the widely used HumanEval coding benchmark.
	- >GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop,
	- >To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents.
	- >Reflection: The LLM examines its own work to come up with ways to improve it.
	  Tool use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.
	  Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).
	  Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.
	- (to this I would also mention human in the loop)
	- [Comments | LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7179159130325078016)
- [JavaScript RAG Web Apps with LlamaIndex - DeepLearning.AI](https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/)
	- [[Retrieval augmented generation]], [[GPT index]]
- [One Agent For Many Worlds, Cross-Species Cell Embeddings, and more](https://www.deeplearning.ai/the-batch/issue-242/)
	- [[Autonomous agent]], [[Flow engineering]], [[Reflection]], [[Tool use]]
	- [Microsoft Absorbs Inflection, Nvidia's New GPUs, Managing AI Bio Risk, and more](https://www.deeplearning.ai/the-batch/issue-243/)
	- [[2401.17464] Efficient Tool Use with Chain-of-Abstraction Reasoning](https://arxiv.org/abs/2401.17464)
- [Accelerating Excellence? - by Dr Philippa Hardman](https://drphilippahardman.substack.com/p/accelerating-excellence)
	- [[Learning Design]], [[Artificial intelligence in education]]
	- >Quality: Learning designs created using Epiphany achieved an average quality score of 4.08 on a 5-point scale, compared to 3.22 for ChatGPT-assisted designs and 2.37 for manual designs.
	- >Speed: The “time to design” (i.e. storyboard) when using Epiphany was on average 72% faster than designing with ChatGPT and 368% faster than traditional, human-only methods.
-